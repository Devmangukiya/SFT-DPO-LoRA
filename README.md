# SFT-DPO-LoRA
Fine-tuned model using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Trained with LoRA adapters for efficient alignment, improving instruction following and human preference adherence. Suitable for chatbots, RAG, and real-world AI applications
